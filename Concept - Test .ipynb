{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28617784-f7e6-409e-a75e-56becf6bfa33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from vivit import ViViT\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch  import nn\n",
    "from torch.utils.data import Dataset\n",
    "import pickle\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "import random\n",
    "import torchvision\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e120dd6c-0321-4f09-8b3b-a62014b1dcd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class skeleton(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(skeleton,self).__init__()\n",
    "        self.project = nn.Linear(34,100)\n",
    "    def forward(self,x):\n",
    "        return self.project(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3832993-ae0e-4273-876e-baced7392a0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class final_head(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(final_head,self).__init__()\n",
    "        self.final = nn.Linear(100,18)\n",
    "    def forward(self,x):\n",
    "        self.final(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541d2548-4583-43b5-9529-7e5d45a73d45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3886119-b8a5-4e60-8931-448fbe117f1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "skeleton_data = torch.randn(10,34)\n",
    "sk_model = skeleton()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "03680c31-c059-40a5-8353-9ac7ad6758fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skeleton(\n",
      "  (project): Linear(in_features=34, out_features=100, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(sk_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffbea0ff-f496-4e0d-8c6f-962a8a00fa47",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of out : torch.Size([10, 100])\n"
     ]
    }
   ],
   "source": [
    "#image_size, patch_size, num_classes, num_frames\n",
    "\n",
    "img = torch.ones([10,16, 3, 224, 320])\n",
    "model = ViViT(320, 8, 100, 16)\n",
    "# parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "# parameters = sum([np.prod(p.size()) for p in parameters]) / 1_000_000\n",
    "# print('Trainable Parameters: %.3fM' % parameters)\n",
    "\n",
    "out = model(img)\n",
    "\n",
    "print(\"Shape of out :\", out.shape)      # [B, num_classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "67c54893-f988-4d66-a2ad-4d33072e236e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34massets\u001b[0m/  module.py     README.md    Test.ipynb\n",
      "LICENSE  \u001b[01;34m__pycache__\u001b[0m/  temporal.py  vivit.py\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "184cd513-d7fa-4d7d-b6f4-fce3dd7fac58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "short_data = \"../test/all_data-hrc.pickle\"\n",
    "data = pickle.load(open(short_data,'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "14f2d646-8bdd-4c1e-9856-848df4f72158",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[\"class_ix\"].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b82ced-6df9-4041-a512-96658c15d21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor([for i in data[\"all_data\"][0][\"video_frames\"].keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d858dee1-c119-4084-b1af-bf89335440d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data[\"all_data\"][0][\"video_frames\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "47d5a096-0df1-46be-890d-fef12c3d83aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "getabuse = [i  for i in data[\"all_data\"] if i[\"video_file_name\"][:5]==\"Abuse\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bbc4c499-095e-474f-97dc-4c30d1ae5d84",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['category_name', 'video_file_name', 'class_idx', 'video_frames', 'person_frame'])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getabuse[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "3a3fa083-4c61-4327-842c-8292208be720",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "b = torchvision.io.read_video(\"../UCF_Videos/Abuse/Abuse002_x264.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "4b61c6af-bc48-4512-9d1d-1581c7082bac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class hrc(Dataset):\n",
    "    #just for abuse\n",
    "    def __init__(self, pickl_list,n_frames):\n",
    "        self.all_data = pickl_list[\"all_data\"]\n",
    "        self.getabuse = [i  for i in self.all_data if i[\"video_file_name\"][:5]==\"Abuse\"]\n",
    "        self.n_frames = n_frames #n_frames to extract from the data and video\n",
    "        self.ix_class = pickl_list[\"ix_class\"]\n",
    "        self.class_ix = pickl_list[\"class_ix\"]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.getabuse)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        video_class = self.getabuse[idx][\"video_file_name\"]\n",
    "        read_video = torchvision.io.read_video(f\"../UCF_Videos/Abuse/{video_class}_x264.mp4\")\n",
    "        # print(read_video[0].size())\n",
    "        trajectory = self.getabuse[idx][\"video_frames\"] #get trajectory of video    \n",
    "        get_trajectory_frames = np.array(list(trajectory.keys()))\n",
    "        min_frame = min(get_trajectory_frames) \n",
    "        max_frame = max(get_trajectory_frames)\n",
    "\n",
    "        frame_start = random.randint(min_frame,max_frame-self.n_frames)\n",
    "        closest_trajectory_ix = np.argmin(abs(frame_start-get_trajectory_frames))\n",
    "        segment_trajectory = get_trajectory_frames[closest_trajectory_ix:closest_trajectory_ix+self.n_frames]\n",
    "\n",
    "        segment_trajectory = torch.Tensor([j for i in segment_trajectory for j in trajectory[i].values()])\n",
    "        final_video = read_video[0][frame_start:frame_start+self.n_frames]/255\n",
    "        final_video = rearrange(final_video,\"f h w c -> f c h w\")\n",
    "        return (final_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6fb660d1-711c-482f-9b08-9f5b47121783",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [j for i in range(5) for j in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "5c5c7d86-e766-4435-b75b-5f745058af89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = hrc(data,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "38f03046-7edf-4152-9e95-9b90368f4b93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# segment = a[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "fc1acde6-f837-4d6d-80c9-3a135201ec40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# frames,trajectory = a[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "d652388c-b022-4bbf-99bb-d81cdce45096",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 3, 240, 320])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[2][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "67bd2009-0347-41e6-a39b-5bde2bfac372",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "frames = frames.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "0f454462-c05b-409d-83c8-2fb4043fcfbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "frames = rearrange(frames,\"b f h w c -> b f c h w\")/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "92ef07f0-a0bb-46b8-959f-cf7ea170940c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(a, batch_size=5, shuffle=True)\n",
    "# test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "afd4cf81-759a-4951-83a5-963d9526c671",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 30, 3, 240, 320])\n"
     ]
    }
   ],
   "source": [
    "for i in train_dataloader:\n",
    "    print(i.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6bcb54-c710-404f-be61-11fa7fd5833d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b3358c7d-1666-4034-9627-a2d36d843a13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#image_size, patch_size, num_classes, num_frames\n",
    "# img = torch.ones([10,30, 3, 224, 320])\n",
    "\n",
    "model = ViViT(320, 16, 13, 30)\n",
    "# parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "# parameters = sum([np.prod(p.size()) for p in parameters]) / 1_000_000\n",
    "# print('Trainable Parameters: %.3fM' % parameters)\n",
    "\n",
    "out = model(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "3220155d-5edf-4725-ad8e-710d122df7e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5124, -0.0861,  0.1992,  0.0496,  1.1429,  0.3310,  0.2900, -0.3958,\n",
      "         -1.0374,  0.3132, -0.2199, -0.0834,  0.4373]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4ca58c-ba0b-4ef7-9ad8-fdbb29517398",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76179093-08e6-4f27-a741-388514c8ade8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
